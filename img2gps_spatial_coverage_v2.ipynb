{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, cv2, imutils, sys, heapq, glob, random\n",
    "from sklearn import svm\n",
    "from sklearn.cluster import MeanShift\n",
    "from skimage.measure import compare_ssim\n",
    "from sklearn import svm\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_nearest_neighbors_func(candidate_images_path, query_image_path, query_image_name, num_nn):\n",
    "\t# cv_query_image = cv2.imread(query_image_path)\n",
    "\t# cv_query_image_resized = cv2.resize(cv_query_image, (100,100), interpolation=cv2.INTER_AREA)\n",
    "\tcv_query_image_resized = cv2.imread(query_image_path)\n",
    "\n",
    "\timage_diff = list()\n",
    "\theapq.heapify(image_diff)\n",
    "\n",
    "\tfor filename in glob.glob(os.path.join(candidate_images_path, '*.jpg')):\n",
    "\n",
    "\t\tcurr_file = filename.strip().split(\"/\")[-1]\t\n",
    "\t\tif curr_file == query_image_name:\n",
    "\t\t\tcontinue\n",
    "\n",
    "\t\tcurr_image = cv2.imread(filename)\n",
    "\n",
    "\t\t(score, diff) = compare_ssim(cv_query_image_resized, curr_image, full=True, multichannel=True)\n",
    "\t\theapq.heappush(image_diff, (score, filename.strip().split(\"/\")[-1], curr_image))\n",
    "# \t\tprint(\"COMPARED TO - \" + curr_file)\n",
    "\n",
    "\treturn (heapq.nlargest(num_nn, image_diff), cv_query_image_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_clusters(nearest_neighbors, candidate_images_path, query_image_path, query_image_name, image_to_gps_dict):\n",
    "\n",
    "\ttraining_set = list()\n",
    "\tcenters = list()\n",
    "\n",
    "\tfor tup in nearest_neighbors:\n",
    "\t\ttraining_set.append(image_to_gps_dict[tup[1]])\n",
    "\n",
    "\tbandwidth = 0.05\n",
    "\ttraining_set = np.array(training_set)\n",
    "\n",
    "\tms = MeanShift(bandwidth=bandwidth,bin_seeding=False)\n",
    "\tms.fit(training_set)\n",
    "\tcenters = ms.cluster_centers_\n",
    "\tlabels = ms.labels_\n",
    "\t\n",
    "\treturn (nearest_neighbors, centers, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_histogram_of_neighbors(nearest_neighbors, query_image_cv, candidate_images_path):\n",
    "\n",
    "\thistograms_of_neighbors = list()\n",
    "\n",
    "\tfor i in range(len(nearest_neighbors)):\n",
    "\t\timage = nearest_neighbors[i][2]\n",
    "\t\timage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\t\thist = cv2.calcHist([image], [0,1,2], None, [8,8,8], [0,256,0,256,0,256])\n",
    "\t\thist = cv2.normalize(hist).flatten()\n",
    "\t\thistograms_of_neighbors.append(hist.tolist())\n",
    "\n",
    "\tquery_image = cv2.cvtColor(query_image_cv, cv2.COLOR_BGR2RGB)\n",
    "\thist_query = cv2.calcHist([query_image], [0,1,2], None, [8,8,8], [0,256,0,256,0,256])\n",
    "\thist_query = cv2.normalize(hist_query).flatten()\n",
    "\n",
    "\treturn (histograms_of_neighbors, hist_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_svm_and_predict(histograms_of_neighbors, hist_query, centers, labels):\n",
    "\n",
    "\tif len(centers)==1:\n",
    "\t\treturn centers[0]\n",
    "\n",
    "\tclf = svm.SVC(decision_function_shape='ovr')\n",
    "\tclf.fit(histograms_of_neighbors, labels)\n",
    "\tdec = clf.decision_function([hist_query])\n",
    "# \tprint \"DEC: \", dec, dec.argmax()\n",
    "\treturn centers[dec.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spatial_data_path = \"./../GSV_Downloaded_spatialdata_v2.txt\"\n",
    "\n",
    "candidate_images_path = \"./../GSV_Downloaded_Resized\"\n",
    "query_image_path = \"./../GSV_Downloaded_Resized_Test_Images\"\n",
    "num_nn = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_to_gps_dict = dict()\n",
    "\n",
    "with open(spatial_data_path, \"r\") as fp:\n",
    "    for line in fp:\n",
    "        data = line.strip().split()\n",
    "        data[0] = data[0].split(\"/\")[-1]\n",
    "        if image_to_gps_dict.get(data[0], None)==None:\n",
    "            image_to_gps_dict[data[0]] = [float(data[1]), float(data[2]), float(data[3]), float(data[4])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_list = list()\n",
    "\n",
    "for file in glob.glob(query_image_path + \"/*.jpg\"):\n",
    "\tfile_list.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in file_list:\n",
    "    query_image_path = filename\n",
    "    query_image_name = query_image_path.strip().split(\"/\")[-1]\n",
    "\n",
    "    # Get neighbors\n",
    "    neighbors, query_image_cv = get_nearest_neighbors_func(candidate_images_path, query_image_path, query_image_name, num_nn)\n",
    "\n",
    "    # Get clusters\n",
    "    neighbors, centers, labels = get_clusters(neighbors, candidate_images_path, query_image_path, query_image_name, image_to_gps_dict)\n",
    "    centers = centers.tolist()\n",
    "    labels = labels.tolist()\n",
    "\n",
    "    # Get histogram of every neighboring image in a numpy list\n",
    "    hist_neighbors, hist_query = get_histogram_of_neighbors(neighbors, query_image_cv, candidate_images_path)\n",
    "\n",
    "    # Return final GPS coordinates after training SVM\n",
    "    prediction = train_svm_and_predict(hist_neighbors, hist_query, centers, labels)\n",
    "    mean_lat = (prediction[0] + prediction[2])/2.0\n",
    "    mean_lng = (prediction[1] + prediction[3])/2.0\n",
    "    prediction[0] = mean_lat - 0.001\n",
    "    prediction[1] = mean_lng - 0.001\n",
    "    prediction[2] = mean_lat + 0.001\n",
    "    prediction[3] = mean_lng + 0.001\n",
    "    \n",
    "    with open(\"predictions_downloaded_dataset_v2.txt\",\"a+\") as fp:\n",
    "        fp.write(query_image_name + \"\\t\" + str(prediction[0]) + \"\\t\" + str(prediction[1]) + \"\\t\" + str(prediction[2]) + \"\\t\" + str(prediction[3]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
